"""
Smart Analysis Recommendation System
æ™ºèƒ½åˆ†ææ¨èç³»ç»Ÿ - åŸºäºæ•°æ®ç‰¹å¾å’Œç”¨æˆ·è¡Œä¸ºæ¨èæœ€ä½³åˆ†ææ–¹æ³•
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
from pathlib import Path

@dataclass
class AnalysisRecommendation:
    """åˆ†ææ¨èç»“æ„"""
    analysis_type: str
    confidence: float
    reason: str
    description: str
    estimated_time: str
    complexity: str  # 'beginner', 'intermediate', 'advanced'
    prerequisites: List[str]
    expected_outputs: List[str]
    priority: int  # 1-5, 5 being highest

class SmartRecommendationEngine:
    """æ™ºèƒ½æ¨èå¼•æ“"""
    
    def __init__(self):
        self.analysis_templates = self._load_analysis_templates()
        self.user_history = {}
        self.data_patterns = {}
        
    def _load_analysis_templates(self) -> Dict:
        """åŠ è½½åˆ†ææ¨¡æ¿"""
        return {
            'differential_expression': {
                'name': 'å·®å¼‚è¡¨è¾¾åˆ†æ',
                'description': 'è¯†åˆ«åœ¨ä¸åŒæ¡ä»¶ä¸‹è¡¨è¾¾å·®å¼‚æ˜¾è‘—çš„åŸºå› ',
                'data_requirements': ['expression', 'clinical'],
                'min_samples': 6,
                'optimal_samples': 20,
                'time_estimate': '5-15åˆ†é’Ÿ',
                'complexity': 'beginner',
                'outputs': ['å·®å¼‚åŸºå› åˆ—è¡¨', 'ç«å±±å›¾', 'çƒ­å›¾', 'GOå¯Œé›†åˆ†æ'],
                'use_cases': ['æ¯”è¾ƒè‚¿ç˜¤vsæ­£å¸¸ç»„ç»‡', 'è¯ç‰©å¤„ç†å‰åå¯¹æ¯”', 'ä¸åŒç–¾ç—…åˆ†æœŸå¯¹æ¯”']
            },
            
            'survival_analysis': {
                'name': 'ç”Ÿå­˜åˆ†æ',
                'description': 'è¯„ä¼°åŸºå› è¡¨è¾¾å¯¹æ‚£è€…é¢„åçš„å½±å“',
                'data_requirements': ['expression', 'clinical_survival'],
                'min_samples': 15,
                'optimal_samples': 50,
                'time_estimate': '3-10åˆ†é’Ÿ',
                'complexity': 'intermediate',
                'outputs': ['Kaplan-Meieræ›²çº¿', 'é£é™©è¯„ä¼°', 'Coxå›å½’ç»“æœ'],
                'use_cases': ['é¢„åæ ‡å¿—ç‰©ç­›é€‰', 'æ²»ç–—æ•ˆæœè¯„ä¼°', 'é£é™©åˆ†å±‚']
            },
            
            'network_analysis': {
                'name': 'ç½‘ç»œåˆ†æ',
                'description': 'æ„å»ºåŸºå› å…±è¡¨è¾¾ç½‘ç»œï¼Œè¯†åˆ«å…³é”®è°ƒæ§èŠ‚ç‚¹',
                'data_requirements': ['expression'],
                'min_samples': 20,
                'optimal_samples': 100,
                'time_estimate': '10-30åˆ†é’Ÿ',
                'complexity': 'advanced',
                'outputs': ['ç½‘ç»œå›¾', 'ä¸­å¿ƒæ€§åˆ†æ', 'æ¨¡å—æ£€æµ‹', 'å…³é”®åŸºå› è¯†åˆ«'],
                'use_cases': ['è°ƒæ§ç½‘ç»œé‡æ„', 'å…³é”®é©±åŠ¨åŸºå› å‘ç°', 'é€šè·¯åˆ†æ']
            },
            
            'immune_analysis': {
                'name': 'å…ç–«å¾®ç¯å¢ƒåˆ†æ',
                'description': 'è¯„ä¼°è‚¿ç˜¤å…ç–«å¾®ç¯å¢ƒç‰¹å¾å’Œå…ç–«ç»†èƒæµ¸æ¶¦',
                'data_requirements': ['expression'],
                'min_samples': 10,
                'optimal_samples': 30,
                'time_estimate': '8-20åˆ†é’Ÿ',
                'complexity': 'intermediate',
                'outputs': ['å…ç–«è¯„åˆ†', 'å…ç–«ç»†èƒæµ¸æ¶¦', 'å…ç–«æ£€æŸ¥ç‚¹åˆ†æ'],
                'use_cases': ['å…ç–«æ²»ç–—é¢„æµ‹', 'å…ç–«çŠ¶æ€è¯„ä¼°', 'å…ç–«é€ƒé€¸æœºåˆ¶']
            },
            
            'drug_response': {
                'name': 'è¯ç‰©å“åº”é¢„æµ‹',
                'description': 'åŸºäºåˆ†å­ç‰¹å¾é¢„æµ‹è¯ç‰©æ•æ„Ÿæ€§',
                'data_requirements': ['expression', 'mutation'],
                'min_samples': 15,
                'optimal_samples': 40,
                'time_estimate': '15-45åˆ†é’Ÿ',
                'complexity': 'advanced',
                'outputs': ['æ•æ„Ÿæ€§è¯„åˆ†', 'è€è¯æœºåˆ¶', 'æ›¿ä»£è¯ç‰©æ¨è'],
                'use_cases': ['ä¸ªæ€§åŒ–ç”¨è¯æŒ‡å¯¼', 'è€è¯æ€§é¢„æµ‹', 'è¯ç‰©é‡å®šä½']
            },
            
            'molecular_subtyping': {
                'name': 'åˆ†å­äºšå‹åˆ†ç±»',
                'description': 'åŸºäºå¤šç»„å­¦æ•°æ®è¿›è¡Œç–¾ç—…åˆ†å­åˆ†å‹',
                'data_requirements': ['expression', 'clinical'],
                'min_samples': 30,
                'optimal_samples': 100,
                'time_estimate': '20-60åˆ†é’Ÿ',
                'complexity': 'advanced',
                'outputs': ['äºšå‹åˆ†ç±»', 'ç‰¹å¾åŸºå› ', 'é¢„åå·®å¼‚', 'æ²»ç–—ç­–ç•¥'],
                'use_cases': ['ç²¾å‡†åˆ†å‹', 'ä¸ªæ€§åŒ–æ²»ç–—', 'é¢„åè¯„ä¼°']
            },
            
            'pathway_analysis': {
                'name': 'é€šè·¯å¯Œé›†åˆ†æ',
                'description': 'è¯†åˆ«æ˜¾è‘—å¯Œé›†çš„ç”Ÿç‰©å­¦é€šè·¯å’ŒåŠŸèƒ½',
                'data_requirements': ['expression'],
                'min_samples': 6,
                'optimal_samples': 20,
                'time_estimate': '5-15åˆ†é’Ÿ',
                'complexity': 'beginner',
                'outputs': ['å¯Œé›†é€šè·¯', 'åŠŸèƒ½æ³¨é‡Š', 'é€šè·¯ç½‘ç»œ', 'å…³é”®åŸºå› '],
                'use_cases': ['åŠŸèƒ½è§£é‡Š', 'æœºåˆ¶æ¢ç´¢', 'é€šè·¯å¯Œé›†']
            },
            
            'multi_omics_integration': {
                'name': 'å¤šç»„å­¦æ•´åˆåˆ†æ',
                'description': 'æ•´åˆå¤šç§ç»„å­¦æ•°æ®è¿›è¡Œç»¼åˆåˆ†æ',
                'data_requirements': ['expression', 'mutation', 'clinical'],
                'min_samples': 25,
                'optimal_samples': 80,
                'time_estimate': '30-90åˆ†é’Ÿ',
                'complexity': 'advanced',
                'outputs': ['æ•´åˆç½‘ç»œ', 'å…³é”®ç‰¹å¾', 'é¢„æµ‹æ¨¡å‹', 'ç”Ÿç‰©å­¦æ´å¯Ÿ'],
                'use_cases': ['ç³»ç»Ÿç”Ÿç‰©å­¦', 'ç»¼åˆè¯Šæ–­', 'å¤šç»´åº¦åˆ†æ']
            }
        }
    
    def analyze_dataset_characteristics(self, dataset_info: Dict) -> Dict:
        """åˆ†ææ•°æ®é›†ç‰¹å¾"""
        
        characteristics = {
            'sample_size': dataset_info.get('samples', 0),
            'feature_count': dataset_info.get('genes', 0),
            'data_types': dataset_info.get('features', {}),
            'quality_score': 0.0,
            'completeness': 0.0,
            'data_balance': 0.0
        }
        
        # è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†
        sample_score = min(1.0, characteristics['sample_size'] / 50)  # 50æ ·æœ¬ä¸ºæ»¡åˆ†
        feature_score = min(1.0, characteristics['feature_count'] / 20000)  # 20kåŸºå› ä¸ºæ»¡åˆ†
        
        # æ•°æ®ç±»å‹å®Œæ•´æ€§
        data_types = characteristics['data_types']
        type_score = 0
        if data_types.get('has_expression', False):
            type_score += 0.4
        if data_types.get('has_clinical', False):
            type_score += 0.3
        if data_types.get('has_mutation', False):
            type_score += 0.2
        if data_types.get('has_methylation', False):
            type_score += 0.1
        
        characteristics['quality_score'] = (sample_score + feature_score + type_score) / 3
        characteristics['completeness'] = type_score
        
        return characteristics
    
    def generate_recommendations(self, dataset_info: Dict, 
                               user_preferences: Dict = None,
                               analysis_history: List = None) -> List[AnalysisRecommendation]:
        """ç”Ÿæˆåˆ†ææ¨è"""
        
        dataset_chars = self.analyze_dataset_characteristics(dataset_info)
        recommendations = []
        
        for analysis_id, template in self.analysis_templates.items():
            recommendation = self._evaluate_analysis_fit(
                analysis_id, template, dataset_chars, 
                user_preferences, analysis_history
            )
            
            if recommendation:
                recommendations.append(recommendation)
        
        # æŒ‰ä¼˜å…ˆçº§å’Œç½®ä¿¡åº¦æ’åº
        recommendations.sort(key=lambda x: (x.priority, x.confidence), reverse=True)
        
        return recommendations[:8]  # è¿”å›å‰8ä¸ªæ¨è
    
    def _evaluate_analysis_fit(self, analysis_id: str, template: Dict, 
                              dataset_chars: Dict, user_preferences: Dict = None,
                              analysis_history: List = None) -> Optional[AnalysisRecommendation]:
        """è¯„ä¼°åˆ†æçš„é€‚åˆåº¦"""
        
        # æ£€æŸ¥æ•°æ®è¦æ±‚
        data_types = dataset_chars['data_types']
        required_types = template['data_requirements']
        
        missing_types = []
        for req_type in required_types:
            if req_type == 'expression' and not data_types.get('has_expression', False):
                missing_types.append('åŸºå› è¡¨è¾¾æ•°æ®')
            elif req_type == 'clinical' and not data_types.get('has_clinical', False):
                missing_types.append('ä¸´åºŠæ•°æ®')
            elif req_type == 'clinical_survival' and not data_types.get('has_clinical', False):
                missing_types.append('ç”Ÿå­˜æ•°æ®')
            elif req_type == 'mutation' and not data_types.get('has_mutation', False):
                missing_types.append('çªå˜æ•°æ®')
        
        # å¦‚æœç¼ºå°‘å¿…éœ€æ•°æ®ç±»å‹ï¼Œé™ä½ç½®ä¿¡åº¦
        if missing_types:
            confidence_penalty = len(missing_types) * 0.3
        else:
            confidence_penalty = 0
        
        # æ£€æŸ¥æ ·æœ¬æ•°é‡
        sample_size = dataset_chars['sample_size']
        min_samples = template['min_samples']
        optimal_samples = template['optimal_samples']
        
        if sample_size < min_samples:
            sample_confidence = 0.3  # æ ·æœ¬ä¸è¶³ï¼Œä½ç½®ä¿¡åº¦
            sample_reason = f"æ ·æœ¬æ•°é‡({sample_size})å°‘äºæ¨èæœ€å°å€¼({min_samples})"
        elif sample_size < optimal_samples:
            sample_confidence = 0.5 + 0.3 * (sample_size - min_samples) / (optimal_samples - min_samples)
            sample_reason = f"æ ·æœ¬æ•°é‡({sample_size})æ¥è¿‘æ¨èå€¼"
        else:
            sample_confidence = 0.8 + 0.2 * min(1, (sample_size - optimal_samples) / optimal_samples)
            sample_reason = f"æ ·æœ¬æ•°é‡({sample_size})å……è¶³"
        
        # åŸºç¡€ç½®ä¿¡åº¦è®¡ç®—
        base_confidence = sample_confidence - confidence_penalty
        
        # ç”¨æˆ·åå¥½è°ƒæ•´
        preference_boost = 0
        if user_preferences:
            if user_preferences.get('complexity_preference') == template['complexity']:
                preference_boost += 0.1
            if analysis_id in user_preferences.get('preferred_analyses', []):
                preference_boost += 0.2
        
        # å†å²åˆ†æè°ƒæ•´
        history_penalty = 0
        if analysis_history:
            recent_analyses = [a for a in analysis_history if a['analysis_type'] == analysis_id]
            if len(recent_analyses) > 2:  # å¦‚æœæœ€è¿‘åšè¿‡å¤šæ¬¡ç›¸åŒåˆ†æï¼Œé™ä½æ¨è
                history_penalty = 0.1
        
        final_confidence = max(0.1, min(1.0, base_confidence + preference_boost - history_penalty))
        
        # ç”Ÿæˆæ¨èç†ç”±
        reasons = []
        if not missing_types:
            reasons.append("âœ… æ•°æ®ç±»å‹åŒ¹é…")
        else:
            reasons.append(f"âš ï¸ ç¼ºå°‘: {', '.join(missing_types)}")
        
        reasons.append(sample_reason)
        
        if dataset_chars['quality_score'] > 0.7:
            reasons.append("âœ… æ•°æ®è´¨é‡è‰¯å¥½")
        elif dataset_chars['quality_score'] > 0.5:
            reasons.append("ğŸ”¸ æ•°æ®è´¨é‡ä¸­ç­‰")
        else:
            reasons.append("âš ï¸ æ•°æ®è´¨é‡éœ€è¦æ”¹å–„")
        
        # ç¡®å®šä¼˜å…ˆçº§
        if final_confidence > 0.8:
            priority = 5
        elif final_confidence > 0.6:
            priority = 4
        elif final_confidence > 0.4:
            priority = 3
        elif final_confidence > 0.2:
            priority = 2
        else:
            priority = 1
        
        return AnalysisRecommendation(
            analysis_type=analysis_id,
            confidence=final_confidence,
            reason="; ".join(reasons),
            description=template['description'],
            estimated_time=template['time_estimate'],
            complexity=template['complexity'],
            prerequisites=missing_types,
            expected_outputs=template['outputs'],
            priority=priority
        )
    
    def get_analysis_workflow_suggestion(self, recommendations: List[AnalysisRecommendation]) -> Dict:
        """å»ºè®®åˆ†æå·¥ä½œæµç¨‹"""
        
        # æŒ‰å¤æ‚åº¦å’Œä¾èµ–å…³ç³»æ’åº
        beginner_analyses = [r for r in recommendations if r.complexity == 'beginner']
        intermediate_analyses = [r for r in recommendations if r.complexity == 'intermediate']
        advanced_analyses = [r for r in recommendations if r.complexity == 'advanced']
        
        workflow = {
            'recommended_order': [],
            'parallel_groups': [],
            'total_estimated_time': '0åˆ†é’Ÿ',
            'description': ''
        }
        
        # æ„å»ºæ¨èé¡ºåº
        order = []
        
        # 1. å…ˆåšåŸºç¡€åˆ†æ
        if beginner_analyses:
            order.extend([r.analysis_type for r in beginner_analyses[:2]])
        
        # 2. å†åšä¸­çº§åˆ†æ
        if intermediate_analyses:
            order.extend([r.analysis_type for r in intermediate_analyses[:2]])
        
        # 3. æœ€ååšé«˜çº§åˆ†æ
        if advanced_analyses:
            order.extend([r.analysis_type for r in advanced_analyses[:1]])
        
        workflow['recommended_order'] = order
        
        # è¯†åˆ«å¯å¹¶è¡Œçš„åˆ†æ
        parallel_groups = []
        if len(beginner_analyses) > 1:
            parallel_groups.append([r.analysis_type for r in beginner_analyses])
        
        workflow['parallel_groups'] = parallel_groups
        
        # ä¼°ç®—æ€»æ—¶é—´
        total_minutes = 0
        for rec in recommendations[:len(order)]:
            time_str = rec.estimated_time
            # ç®€å•è§£ææ—¶é—´å­—ç¬¦ä¸² (ä¾‹å¦‚: "5-15åˆ†é’Ÿ")
            if '-' in time_str and 'åˆ†é’Ÿ' in time_str:
                time_parts = time_str.replace('åˆ†é’Ÿ', '').split('-')
                avg_time = (int(time_parts[0]) + int(time_parts[1])) / 2
                total_minutes += avg_time
        
        workflow['total_estimated_time'] = f"{int(total_minutes)}åˆ†é’Ÿ"
        
        # ç”Ÿæˆæè¿°
        if len(order) > 0:
            workflow['description'] = f"""
            å»ºè®®æŒ‰ä»¥ä¸‹é¡ºåºè¿›è¡Œåˆ†æï¼š
            1. ä»åŸºç¡€åˆ†æå¼€å§‹å»ºç«‹æ•°æ®æ¦‚è§ˆ
            2. è¿›è¡Œä¸­çº§åˆ†ææ·±å…¥ç†è§£æ•°æ®
            3. æœ€åè¿›è¡Œé«˜çº§åˆ†æè·å¾—æ·±å±‚æ´å¯Ÿ
            
            é¢„è®¡æ€»è€—æ—¶çº¦ {workflow['total_estimated_time']}
            """
        
        return workflow
    
    def get_contextual_tips(self, analysis_type: str, dataset_info: Dict) -> List[str]:
        """è·å–ä¸Šä¸‹æ–‡ç›¸å…³çš„åˆ†ææç¤º"""
        
        tips = []
        template = self.analysis_templates.get(analysis_type, {})
        sample_size = dataset_info.get('samples', 0)
        
        # æ ·æœ¬æ•°é‡ç›¸å…³æç¤º
        if sample_size < template.get('min_samples', 0):
            tips.append(f"ğŸ’¡ å½“å‰æ ·æœ¬æ•°é‡({sample_size})è¾ƒå°‘ï¼Œç»“æœå¯èƒ½ä¸å¤Ÿç¨³å®šï¼Œå»ºè®®å¢åŠ æ ·æœ¬æˆ–é™ä½ç»Ÿè®¡é˜ˆå€¼")
        
        if sample_size > template.get('optimal_samples', 50):
            tips.append(f"âœ¨ æ ·æœ¬æ•°é‡({sample_size})å……è¶³ï¼Œå¯ä»¥è¿›è¡Œæ›´æ·±å…¥çš„å­ç¾¤åˆ†æ")
        
        # æ•°æ®ç±»å‹ç›¸å…³æç¤º
        data_types = dataset_info.get('features', {})
        
        if analysis_type == 'survival_analysis' and not data_types.get('has_clinical'):
            tips.append("âš ï¸ ç”Ÿå­˜åˆ†æéœ€è¦ä¸´åºŠæ•°æ®ï¼Œå»ºè®®å…ˆä¸Šä¼ åŒ…å«ç”Ÿå­˜ä¿¡æ¯çš„ä¸´åºŠæ•°æ®")
        
        if analysis_type == 'drug_response' and not data_types.get('has_mutation'):
            tips.append("ğŸ’Š æ·»åŠ çªå˜æ•°æ®å¯ä»¥æ˜¾è‘—æé«˜è¯ç‰©å“åº”é¢„æµ‹çš„å‡†ç¡®æ€§")
        
        if analysis_type == 'immune_analysis':
            tips.append("ğŸ›¡ï¸ å…ç–«åˆ†æç»“æœå¯ä»¥ä¸ç”Ÿå­˜åˆ†æç»“åˆï¼Œè¯„ä¼°å…ç–«å¾®ç¯å¢ƒå¯¹é¢„åçš„å½±å“")
        
        # å¤æ‚åº¦ç›¸å…³æç¤º
        complexity = template.get('complexity', 'beginner')
        if complexity == 'advanced':
            tips.append("ğŸš€ è¿™æ˜¯é«˜çº§åˆ†æï¼Œå»ºè®®å…ˆå®ŒæˆåŸºç¡€åˆ†æå»ºç«‹æ•°æ®æ¦‚è§ˆ")
        
        if complexity == 'beginner':
            tips.append("ğŸ¯ è¿™æ˜¯å…¥é—¨çº§åˆ†æï¼Œé€‚åˆå¿«é€Ÿäº†è§£æ•°æ®ç‰¹å¾")
        
        # é€šç”¨æç¤º
        tips.append("ğŸ“Š åˆ†æå®Œæˆåï¼Œå¯ä»¥åœ¨å¯è§†åŒ–é¡µé¢æŸ¥çœ‹è¯¦ç»†ç»“æœ")
        tips.append("ğŸ’¾ è®°å¾—ä¿å­˜åˆ†æç»“æœä»¥ä¾¿åç»­æ¯”è¾ƒå’Œå¼•ç”¨")
        
        return tips[:4]  # è¿”å›æœ€å¤š4ä¸ªæç¤º

# å…¨å±€å®ä¾‹
recommendation_engine = SmartRecommendationEngine()